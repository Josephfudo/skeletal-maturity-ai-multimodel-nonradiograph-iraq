import numpy as np
import xgboost as xgb
import optuna
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import os
import pickle
import torch
import warnings

"""
This script performs hyperparameter tuning for the Level-2 XGBoost meta-model.

It uses the 25-feature dataset generated by 'create_stacking_features_v3.py'.
It will run N_TRIALS using Optuna to find the best possible set of
hyperparameters for XGBoost, validating against the OOF training set.

Finally, it trains one last model on the *full* OOF training set with
the best parameters and evaluates it on the test set for a final score.
"""

# --- CONFIGURATION ---
N_TRIALS = 100  # Number of tuning trials to run
N_SPLITS = 5   # Number of folds for cross-validation *within the tuning loop*

# --- V3 FILE PATHS (25 FEATURES) ---
TRAIN_FEAT_FILE = 'oof_train_features_v3.npy'
TRAIN_LBL_FILE = 'oof_train_labels_v3.npy'
TEST_FEAT_FILE = 'oof_test_features_v3.npy'
TEST_LBL_FILE = 'oof_test_labels_v3.npy'
# ---

# 1. Load the full OOF training data for tuning
print(f"Loading OOF training data from {TRAIN_FEAT_FILE}...")
try:
    X_train_oof = np.load(TRAIN_FEAT_FILE)
    y_train_oof = np.load(TRAIN_LBL_FILE)
except FileNotFoundError:
    print(f"FATAL ERROR: Could not find {TRAIN_FEAT_FILE}.")
    print("Please run 'create_stacking_features_v3.py' first.")
    exit()

print(f"Loaded training features with shape: {X_train_oof.shape}")
if X_train_oof.shape[1] != 25:
    print(f"WARNING: Expected 25 features, but found {X_train_oof.shape[1]}.")
    print("Are you sure you are loading the '_v3' files?")


def objective(trial):
    """
    Optuna objective function.
    This will be called once per trial.
    """
    
    # Define the hyperparameter search space for XGBoost
    param = {
        'objective': 'multi:softmax',
        'num_class': 3,
        'eval_metric': 'mlogloss',
        'tree_method': 'hist',
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
        'n_estimators': trial.suggest_int('n_estimators', 200, 2000, step=100),
        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0, step=0.05),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0, step=0.05),
        'gamma': trial.suggest_float('gamma', 0, 0.5, step=0.05),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),  # L1
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True), # L2
    }
    
    warnings.filterwarnings('ignore', category=UserWarning, module='xgboost')
    
    model = xgb.XGBClassifier(**param)
    
    # We evaluate this trial using 5-fold cross-validation on the OOF training data.
    # This gives a robust estimate of this hyperparameter set's performance.
    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)
    
    # We use the unscaled data, as XGBoost is not sensitive to feature scaling.
    scores = cross_val_score(model, X_train_oof, y_train_oof, n_jobs=-1, cv=skf, scoring='accuracy')
    
    return scores.mean()


def run_tuning():
    print(f"\n--- Starting Optuna Tuning for XGBoost Meta-Model ---")
    print(f"Running {N_TRIALS} trials with {N_SPLITS}-fold CV...")
    
    # Create the study and run the optimization
    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())
    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)

    print(f"\n--- Tuning Complete ---")
    print(f"Best CV accuracy: {study.best_value * 100:.4f}%")
    print("Best parameters found:")
    print(study.best_params)
    
    # --- Final Model Training ---
    print("\n--- Training final tuned XGBoost model on all OOF data... ---")
    
    # Load test data for final evaluation
    try:
        X_test = np.load(TEST_FEAT_FILE)
        y_test = np.load(TEST_LBL_FILE)
    except FileNotFoundError:
        print(f"FATAL ERROR: Could not find {TEST_FEAT_FILE}.")
        return

    # Get best params and add back fixed ones
    best_params = study.best_params
    best_params.update({
        'objective': 'multi:softmax',
        'num_class': 3,
        'eval_metric': 'mlogloss',
        'tree_method': 'hist',
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
        'early_stopping_rounds': 50, # <-- ADD THIS LINE
        'verbose': False             # <-- ADD THIS LINE to suppress fit messages
    })

    final_model = xgb.XGBClassifier(**best_params)

    # Train on the FULL OOF set
    final_model.fit(
        X_train_oof, y_train_oof,
        eval_set=[(X_train_oof, y_train_oof)]
        # early_stopping_rounds=50, <-- REMOVE THIS LINE
        # verbose=False             <-- REMOVE THIS LINE
    )
    
    # --- Final Evaluation ---
    print("\n--- FINAL TUNED STACKED MODEL RESULTS (XGBoost) ---")
    y_pred_final = final_model.predict(X_test)
    
    accuracy_final = accuracy_score(y_test, y_pred_final)
    report_final = classification_report(
        y_test, 
        y_pred_final, 
        target_names=['Pre-peak', 'Peak', 'Post-peak'],
        digits=4
    )
    cm_final = confusion_matrix(y_test, y_pred_final)

    print(f"Final Tuned Stacked Test Accuracy (XGBoost): {accuracy_final * 100:.4f}%")
    print("\nClassification Report (XGBoost):")
    print(report_final)
    print("\nConfusion Matrix (XGBoost):")
    print(cm_final)
    
    # Save the new, tuned model
    tuned_model_filename = 'stacking_meta_model_xgb_v3_tuned.pkl'
    with open(tuned_model_filename, 'wb') as f:
        pickle.dump(final_model, f)
    print(f"\nSaved tuned meta-model to '{tuned_model_filename}'")

if __name__ == "__main__":
    # Suppress Optuna's trial info logs for a cleaner output
    optuna.logging.set_verbosity(optuna.logging.WARNING)
    run_tuning()